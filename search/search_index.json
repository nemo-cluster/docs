{"config":{"lang":["en","de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documents and Documentation","text":"<p>This page is for documentation of NEMO and a document generator.</p>"},{"location":"betriebskonzept/","title":"Betriebskonzept","text":"G\u00fcltig ab: Version: 0.4.4 Datum: 21.06.2021 <p>TLP:AMBER</p> <p>Limited disclosure, restricted to participants' organizations. Distribution outside this audience requires written permission from the originator.</p> Version Datum Autor*innen \u00c4nderungen 0.4.4 21.06.2021 MJ Anf\u00fchrungszeichen korrigiert. 0.4.3 25.05.2021 MJ,DvS Kleinere Textkorrekturen. Testglossar zu Tooltipps ge\u00e4ndert. 0.4.2 21.05.2021 MJ Weitere Korrekturen, die durch die Konversion von Latex zu rST notwendig wurden. Fu\u00dfnoten nach Punkt. Testweise Glossar erstellt. 0.4.1 21.05.2021 JL Kleinere Korrekturen 0.4.0 20.04.2021 MJ Einleitung gestrafft, theoretische Sicherheitszonen entfernt, zus\u00e4tzliche Dokumente und Fu\u00dfnoten, TOMs ausgelagert, Ziele und Ergebnisse nach vorne gezogen, neue Abschnitte zu Updates und Workspaces. 0.3.2 25.03.2021 MJ Korrekturen, Erg\u00e4nzungen. 0.3.1 19.03.2021 DvS Korrekturen, Erg\u00e4nzungen. 0.3.0 13.03.2021 DvS Umstrukturierung des Textes, st\u00e4rkere Verkn\u00fcpfung von Sicherheit und Betriebsmodell, Erg\u00e4nzungen. 0.2.1 09.03.2021 BW, JL, DvS, MJ Anmerkungen und Korrekturen. 0.2.0 09.03.2021 DvS Erg\u00e4nzungen u.a. aus dem DFN-Paper zu Security-Domains und Absicherungskonzept. 0.1.0 06.03.2021 MJ Erster Entwurf basierend auf Informationen des Betriebskonzepts de.NBI-FR und einer Vorlage von TOMs aus T\u00fcbingen."},{"location":"betriebskonzept/#einleitung","title":"Einleitung","text":"<p>Das Konzept, auf dessen Grundlage das bwForCluster NEMO betrieben wird, geht auf \u00dcberlegungen in der Abteilung eScience des Rechenzentrums der Universit\u00e4t Freiburg (RZ) zur\u00fcck und wurde in verschiedenen Projekten iterativ entwickelt.<sup>1</sup> Die f\u00fcr den bwForCluster NEMO\u00a0beschaffte Hardware - Rechenknoten, Speichersystem f\u00fcr wissenschaftliche Daten und Infrastrukturserver - wird in Datenschr\u00e4nken untergebracht, die vom RZ in hierf\u00fcr dedizierten R\u00e4umlichkeiten betrieben werden. Die Datenschr\u00e4nke werden vom RZ betreut und auf grundlegende Betriebsbereitschaft (Strom, K\u00fchlung) \u00fcberwacht. Es werden prim\u00e4r zwei gro\u00dfe Speichersysteme genutzt, einerseits eine professionelle Storage-Appliance f\u00fcr administrative und Nutzer*innendaten, andererseits ein schnelles paralleles Dateisystem f\u00fcr die Nutzung durch Compute-Jobs. Auf den Infrastrukturservern laufen diverse Dienste, die skriptgesteuert mit Ansible-Rezepten installiert und konfiguriert werden. Die Rechenknoten werden via netzwerkbasiertem Remote-Boot von dedizierten Infrastrukturservern zustandslos betrieben. Auf diesen Knoten werden die Jobs der Wissenschaftler*innen ausgef\u00fchrt. Besonders der Anspruch, Daten \u00fcber l\u00e4ngere Zeitr\u00e4ume hinweg in ihren Entstehungs- und Verarbeitungskontexten reproduzierbar zu halten, f\u00fchrte zu einer Komplementierung des traditionellen Betriebsmodells von HPC-Systemen um virtuelle Maschinen und Container. In diesen Virtualisierten (VFU) und Containerisieten (CFU) Forschungsumgebungen laufen die Anwendungen oder Umgebungen, die von den Wissenschafter*innen kontrolliert werden.<sup>2</sup><sup>3</sup><sup>4</sup></p> <p>Innerhalb dieser Forschungsumgebungen haben Wissenschaftler*innen die Freiheit, Forschungsdaten und deren Kontext so zu abstrahieren, dass sie auf anderen Systemen weiter ausgef\u00fchrt und reproduziert werden k\u00f6nnen. Mit VFUs und CFUs werden Hardware, Software und Dienste so entkoppelt, dass f\u00fcr den bwForCluster NEMO\u00a0ein verbessertes Management von Ressourcen erreicht wird. Ein Grundgedanke dieser konzeptionellen Vor\u00fcberlegungen ist die Aufteilung in Schichten. Der hier vorgestellte Dienst des bwForClusters NEMO\u00a0deckt im Modell, das in<sup>5</sup><sup>6</sup> vorgestellt wurde, die Ebene der IT-Ressourcen ab. F\u00fcr die Betriebsorganisation wird sie innerhalb des bwForClusters NEMO\u00a0weiter differenziert in Schrank, Hardware und Dienste. Dieses Konzeptpapier beschreibt den Betrieb des bwForClusters NEMO.</p>"},{"location":"betriebskonzept/#ziele-im-sinne-der-informationssicherheit","title":"Ziele im Sinne der Informationssicherheit","text":"<p>Kernanliegen des bwForClusters NEMO\u00a0ist, Forscher*innen den Zugang zu Rechen- und Speicherkapazit\u00e4ten zu geben. Als Schutzziel betrachtet, ist dies die Sicherstellung der Verf\u00fcgbarkeit von Rechenressourcen, auf denen Forscher*innen ihre Rechenjobs ausf\u00fchren. Als Dienstanbieter muss das bwForCluster NEMO\u00a0eine Verf\u00fcgbarkeit bieten, die Wissenschaftler*innen Big-Data-Analysen \u00fcber das Ma\u00df selbst gemanagter oder dezentral in Forschungseinrichtung administrierten IT-Cluster hinaus erm\u00f6glicht.</p> <p>F\u00fcr die Forscher*innen ist, um ihre Datenverarbeitung und Ergebnisse reproduzierbar zu halten, eine Integrit\u00e4t von Daten auf Speicherebene notwendig. F\u00fcr Integrit\u00e4t von Daten auf der von ihnen betriebenen Verarbeitungsschicht sind sie selbst verantwortlich.</p> <p>Das Schutzziel Vertraulichkeit bezieht sich auf die Kontrolle des Zutritts, Zugangs und Zugriffs sowie die Trennung von Umgebungen. Mit der Abstraktion der Dienstschichten - Konzentration auf der Ebene der physischen und netztechnischen Infrastrukturen, der Clusteradministration in HPC, der Entkoppelung von logischen Nutzer-bezogenen Einheiten - sind Arbeitsteilungen m\u00f6glich, die ein gr\u00f6\u00dferes Spektrum an Diensten f\u00fcr die Forschung in den Bereich des wirtschaftlich m\u00f6glichen schieben. Sicherheitsrelevante Arbeitsbereiche k\u00f6nnen zentral von qualifiziertem Personal abgedeckt werden.</p> <p>Regulatorische Anforderungen an Forschung im Bereich der Neurowissenschaft, die in einigen Bereichen personenbezogene medizinische Daten mit hohem Schutzbedarf erzeugen, erfordern die Sicherstellung, diese Daten innerhalb eines kontrollierbaren Rechtsraums zu speichern. Die Souver\u00e4nit\u00e4t wird auf die Kontrolle der physischen, organisatorischen und operativen Aspekte bezogen.</p> <p>Das bwForCluster NEMO\u00a0ist mit diesen \u00dcberlegungen in der Lage, die aus den strategischen Zielen abgeleiteten Schutzziele mit eigenen Ma\u00dfnahmen wirtschaftlich tragen und erreichen zu k\u00f6nnen. Das Dokument \"Technisch Organisatorische Ma\u00dfnahmen - bwForCluster NEMO\" geht auf die einzelnen Schutzziele detaillierter ein.</p>"},{"location":"betriebskonzept/#erwartete-ergebnisse","title":"Erwartete Ergebnisse","text":"<p>Mit dem Aufbau der Teildienste in technischen Schichten und der flexiblen Boot-Prozedur k\u00f6nnen die strategischen Ziele des bwForClusters NEMO\u00a0mit den gegebenen Ressourcen erreicht und die Informationssicherheit gewahrt werden. Die Gliederung der Schichten erlaubt es, die Arbeitsbereiche zu trennen und die Risiken im Betrieb einzelner Schichten besser zu isolieren. Besonders die im Wissenschaftsbereich hohe Erwartung an Verf\u00fcgbarkeit l\u00e4sst sich besser erreichen. Die Zahl der \"Single Points of Failures\" ist besser kontrollierbar. Die Standardisierung in der Steuerung der Hardware reduziert die Komplexit\u00e4t im Betrieb, die den Wissenschaftler*innen gebotene Freiheit ist praktisch vollst\u00e4ndig von der Betriebsschicht getrennt. Die Abstraktion reduziert Angriffsvektoren auf die Betriebsschicht, die durch Ereignisse auf der Ebene der Wissenschaftler*innen er\u00f6ffnet werden.</p>"},{"location":"betriebskonzept/#dienstbeschreibung-hpc","title":"Dienstbeschreibung HPC","text":"<p>Es liegt eine Dienstbeschreibung f\u00fcr das HPC-Computing-Angebot des Rechenzentrums im Rahmen des allgemeinen Servicekatalogs vor. Diese kann online von den Seiten des Rechenzentrums abgerufen werden.<sup>7</sup> Diese Dienstbeschreibung wird einem regelm\u00e4\u00dfigen Review-Prozess in der Runde der Abteilungsleiter*innen unterzogen.</p>"},{"location":"betriebskonzept/#betriebsmodell-bwforcluster-nemo","title":"Betriebsmodell bwForCluster NEMO","text":"<p>Das Betriebsmodell beschreibt konkrete Schritte des Deployments und der t\u00e4glichen Produktion des HPC-Clusters. Hierzu wird eine Kombination aus administrativen Infrastruktur (Server) und von den Wisschenschaftler*inenn zu Berechnungen verwendeten Rechenknoten eingesetzt.</p>"},{"location":"betriebskonzept/#hardware-und-dienste","title":"Hardware und Dienste","text":"<p>Die installierte Hardware des bwForClusters NEMO\u00a0besteht aus \u00fcber 900 Rechenknoten und einigen dedizierten Servern f\u00fcr NEMO-Dienste.<sup>8</sup> Virtuelle Maschinen als VFUs und Container (CFUs) werden ebenfalls auf diesen Rechenknoten ausgef\u00fchrt, wie regul\u00e4re Cluster-Jobs. Auf den Rechenknoten (ausgenommen Knoten f\u00fcr interaktive Nutzung) werden immer nur Jobs eines/einer Nutzers/Nutzerin ausgef\u00fchrt. Zugang zum Cluster erfolgt \u00fcber sogenannte Login-Knoten,</p> <pre><code>login1.nemo.uni-freiburg.de (alias login.nemo.uni-freiburg.de)\nlogin2.nemo.uni-freiburg.de\n</code></pre> <p>den Visualisierungsknoten (Vis),</p> <pre><code>vis1.nemo.uni-freiburg.de\nvis2.nemo.uni-freiburg.de\n</code></pre> <p>und \u00fcber das Openstack-Dashboard. Die Zugangsknoten sind im \u00f6ffentlichen Internet exponiert, welches jedoch auf das Belw\u00fc-Netz eingeschr\u00e4nkt wurde.<sup>9</sup> Der Zugriff erfolgt prim\u00e4r \u00fcber den SSH-Dienst. Beim Openstack-Dashboard wird der Transport mit HTTPS abgesichert.</p>"},{"location":"betriebskonzept/#ausgewahlte-dienste","title":"Ausgew\u00e4hlte Dienste","text":""},{"location":"betriebskonzept/#ssh","title":"SSH","text":"<p>Dieser Dienst l\u00e4uft auf allen Knoten und Servern. Mit ihm ist ein Login von Wissenschaftler*innen und Administrator*innen \u00fcber die Eingabe von Nutzername und Dienst-Passwort oder einen SSH-Key m\u00f6glich.</p>"},{"location":"betriebskonzept/#scheduler","title":"Scheduler","text":"<p>Dieser Dienst ist auf dem Management-Server von NEMO\u00a0aktiv und dient zum \"Scheduling\" (Verteilen nach vorgegebenem Algorithmus) von Jobs auf dem Cluster. Dazu sind auf den Rechenknoten Clients installiert, die Jobs und Ressourcenverbrauch protokollieren und diese Information an den Scheduler zur\u00fcckmelden.</p>"},{"location":"betriebskonzept/#https","title":"HTTP(S)","text":"<p>Das OpenStack-Dashboard ist als Webschnittstelle umgesetzt und setzt f\u00fcr den Zugriff auf HTTPS, um eine Absicherung bei der Nutzung \u00fcber das \u00f6ffentliche Belw\u00fc-Netz zu erreichen. Der Zugang erfolgt \u00fcber Nutzername und Dienst-Passwort. Auf dem Deployment-Server wird HTTP verwendet, um Konfigurationen zu den Rechenknoten zu verteilen (Teil des iPXE-basierten Boot-Ablaufs und der individuellen Knotenkonfiguration). Die Deployment-Server sind nur im internen NEMO-Netz erreichbar.</p>"},{"location":"betriebskonzept/#dnbd3","title":"DNBD3","text":"<p>Auf den Deployment-Servern laufen zwei Distributed-Network-Block-Device-3-Instanzen. Dieser Dienst stellt das Betriebssystem f\u00fcr Login-, Vis- und Rechenknoten zur Verf\u00fcgung. Eine redundante Auslegung stellt sicher, dass bei Ausfall eine Servers das Cluster weiterhin mit dem Betriebssystem-Image versorgt wird.</p>"},{"location":"betriebskonzept/#ansible","title":"Ansible","text":"<p>Auf dem Management-Server \u00fcbernimmt Ansible das Ausrollen der Dienste und deren Konfiguration.</p>"},{"location":"betriebskonzept/#openstack","title":"OpenStack","text":"<p>Mehrere Openstack-Server und -Dienste sind Cluster-intern f\u00fcr die Nutzung von VFUs zust\u00e4ndig.</p>"},{"location":"betriebskonzept/#dhcp","title":"DHCP","text":"<p>Die IP-Adressen werden bei Rechen-, Login-, sowie Visualisierungsknoten \u00fcber DHCP verteilt. Dieser Dienst wird von der Abteilung \"Netze und Kommunikationsdienste\" mithilfe der Appliance Infoblox betrieben.<sup>10</sup></p>"},{"location":"betriebskonzept/#monitoring","title":"Monitoring","text":"<p>Der Monitoring-Server empf\u00e4ngt und speichert alle Log- und Protokoll-Dateien. Hierbei werden Login-Versuche, kritische Fehler und Hardware-Parameter protokolliert und teilweise visualisiert. F\u00fcr einfache Parameter wie die Temperatur eines Knotens sind Grenzwerte definiert. Bei \u00dcberschreitung dieser werden die Administrator*innen des Clusters per Mail verst\u00e4ndigt.</p>"},{"location":"betriebskonzept/#deployment","title":"Deployment","text":"<p>Die Dienste beim bwForCluster NEMO\u00a0werden \u00fcber Ansible-Rollen auf den Serverknoten aufgesetzt. Das erm\u00f6glicht ein schnelles und einfaches Ausrollen auf neuen Servern. Es m\u00fcssen nur wenige Anpassungen durchgef\u00fchrt werden.</p> <p>Das Boot- und Betriebssystem der Rechenknoten wird ebenfalls \u00fcber Ansible generiert. Hierzu wird das CentOS-Vorlagen-Image mit Ansible konfiguriert und in in ein lesbares QCOW2-Image konvertiert.<sup>11</sup> Mit dem in der Abteilung \"eScience\" entwickelten Boot-Framework wird dann das Image \u00fcber das Netzwerk gestartet. Das Image wird dabei \u00fcber das nur lesbare Blockdevice DNBD3 eingebunden. F\u00fcr Schreiboperationen wird eine Copy-on-write-Schicht dar\u00fcber gelegt, die bei jedem Boot eines Knotens frisch initialisiert wird. Alle neu generierten Images bekommen eine inkrementierte Revisionsnummer, so dass die Umgebung zum einen reproduzierbar ist, zum anderen bei Problemen mit einer Revision einfach auf eine \u00e4ltere zur\u00fcck gegriffen werden kann.</p> <p>Die Entscheidung, welche Systemversion, Revision und Konfiguation geladen wird, trifft der sogenannte Bootauswahlserver anhand der Zugeh\u00f6rigkeit der MAC-Adresse der Netzwerkkarte, \u00fcber die der initiale Start lief, zu einer Boot-Gruppe.<sup>12</sup> Diese Information wird jedesmal beim Boot ausgewertet. Die Boot-Gruppe entscheidet \u00fcber die Konfiguration des Knotens. Sie wird verwendet, um spezielle Knoten zu konfigurieren, beispielsweise bei GPU-Knoten. Bei neuer Hardware durch Neubeschaffungen oder Ersatz bei Reparaturen muss lediglich die MAC-Adresse einer Gruppe zugeordnet werden. Neue Konfigurationen k\u00f6nnen ebenfalls schnell eingerichtet werden, da nur die zur Basisgruppe unterschiedliche Konfiguration vorgenommen werden muss.</p>"},{"location":"betriebskonzept/#changemanagement","title":"Changemanagement","text":"<p>Der Deploymentprozess erleichtert das Changemanagement. Die Bereitstellung des Basissystems erlaubt schnelle Funktionstests, da beim Netzwerk-Boot lediglich die neuere Version angefahren werden muss. Die Hardwaregrundlage der Rechenknoten ver\u00e4ndert sich im Laufe der Beschaffungszyklen, jedoch wird im Beschaffungsprozess und beim Design des Basissystems darauf geachtet, dass neue Knoten ohne Br\u00fcche in das Grundsystem \u00fcbernommen werden k\u00f6nnen. Die Heterogenit\u00e4t wird durch den kontinuierlichen Austausch von Hardware verursacht, f\u00fcr die jeweils die zum Moment der Beschaffung g\u00fcnstigsten oder passendsten Komponenten verwendet werden.</p> <p>F\u00fcr jede Ger\u00e4teklasse wird ein Knoten reserviert, mit dem ausschlie\u00dflich Tests durchgef\u00fchrt werden. Erst wenn bei \u00c4nderungen am Grundsystem oder Patches auf den reservierten Knoten durchgetestet wurden, werden diese \u00c4nderungen auf den produktiven Knoten ausgerollt.</p>"},{"location":"betriebskonzept/#updates-und-sicherheit","title":"Updates und Sicherheit","text":"<p>Bei allen Servern, die keinen direkten Zugriff durch die Wissenschaftler*innen erlauben, werden Updates bei den gr\u00f6\u00dferen Wartungen eingespielt, die \u00fcblicherweise ein bis zwei Mal im Jahr statt finden. Sollte eine au\u00dferordentliche Sicherheitsl\u00fccke bestimmte Dienste betreffen, wird das Update sobald es verf\u00fcgbar ist, eingespielt. Sollte hierzu ein Herunterfahren des Clusters notwendig werden, kann sich das Update um bis zu vier Tage verz\u00f6gern. Das Vorgehen wird dann im eScience-Team unter Zuhilfenahme zus\u00e4tzlicher IT-Experten diskutiert. Diese Wartungen werden an die Wissenschaftler*innen vorab kommuniziert.</p> <p>Bei den Login-, Vis- und Rechenknoten werden monatliche Updates eingespielt. Dabei findet ein Rolling-Update statt. Das Cluster wird offline genommen und neue Jobs k\u00f6nnen erst wieder starten, wenn die Rechenknoten mit der neuen Systemversion gebootet sind. Damit k\u00f6nnen alte Jobs noch zu Ende laufen, neue Jobs jedoch nur noch in der neuen Umgebung starten. Durch das Deployment und Changemanagement kann bei Problemen auf eine \u00e4ltere Version gewechselt werden. Bei au\u00dferordentlichen Sicherheitsl\u00fccken wird das Update, sobald es verf\u00fcgbar ist, eingespielt und ausgerollt. Durch dieses Rolling-Update sind die Patches bei allen Knoten eingespielt, wenn der Job, der zum Zeitpunkt des Ausrollens noch die l\u00e4ngste Restlaufzeit besitzt, endet und die vom Job verwendeten Knoten neu booten k\u00f6nnen. Da die derzeitige maximale Laufzeit der Jobs vier Tage betr\u00e4gt, ist ein regul\u00e4res Update sp\u00e4testens nach vier Tagen beendet.</p>"},{"location":"betriebskonzept/#parallel-und-home-speicher","title":"Parallel- und HOME-Speicher","text":"<p>Die HOME-Verzeichnisse der Nutzer*innen liegen auf dem Isilon-Speicher der Universit\u00e4t.<sup>13</sup> F\u00fcr die aktuell verarbeiteten wissenschaftlichen Daten dient ein zentraler Parallelspeicher, der auf BeeGFS aufsetzt.<sup>14</sup> Anders als der Isilon-Speicher ist der parallele Speicher nur durch ein RAID6 abgesichert und bietet keine weiteren Backups. Auf diesem Speicher sollten nur Daten liegen, die unmittelbar f\u00fcr Berechnungen ben\u00f6tigt werden. F\u00fcr eine anschlie\u00dfende Speicherung der auf dem Cluster nicht mehr ben\u00f6tigten Daten wird bis Ende 2021 eine L\u00f6sung auf dem bwSFS angeboten.<sup>15</sup></p> <p>Der Parallelspeicher ist neben dem bwForCluster NEMO\u00a0ebenfalls in der ATLAS-Umgebung eingebunden. Diese beinhaltet das ATLAS-Cluster und die ATLAS-VFU.<sup>16</sup> Dadurch k\u00f6nnen zus\u00e4tzlich Nutzer*innen und Administrator*innen der Freiburger ATLAS-Gruppen auf diesen Speicher zugreifen.</p> <p>Nutzer*innen k\u00f6nnen in der Standardeinstellung nur ihre eigenen Daten einsehen und bearbeiten. Administrator*innen k\u00f6nnen alle Daten, sofern sie nicht Nutzer- oder Client-seitig verschl\u00fcsselt wurden, einsehen und bearbeiten. Beide Speicher werden nicht standardm\u00e4\u00dfig verschl\u00fcsselt.</p>"},{"location":"betriebskonzept/#workspaces","title":"Workspaces","text":"<p>Die Daten, die auf dem parallelen Speicher liegen, werden f\u00fcr die Berechnungen der Wissenschaftler*innen ben\u00f6tigt. Das Management der Daten wird durch die Forscher*innen in sogenannten \"Workspaces\" durchgef\u00fchrt.<sup>17</sup> Die Nutzer*innen m\u00fcssen Workspaces anlegen, um den parallelen Speicher verwenden zu k\u00f6nnen. Dabei kann ein Workspace maximal 100 Tage g\u00fcltig sein. Es besteht jedoch die M\u00f6glichkeit, jeden Workspace 99\u00a0mal 100 Tage zu verl\u00e4ngern. Die Wissenschaftler*innen werden 7 Tage vor Ablauf eines Workspaces per Mail informiert.</p> <p>Es wird empfohlen, f\u00fcr unterschiedliche Unterprojekte und separate Berechnungen eigene Workspaces anzulegen. Jeder Workspace kann damit in einem sp\u00e4teren Schritt als separate Einheit oder Objekt mit Metadaten versehen in einem Wissenschaftsspeicher wie bwSFS gesichert werden. Sinnvolle Einheiten/Workspaces m\u00fcssen durch die Wissenschaftler*innen selbst definiert werden.</p>"},{"location":"betriebskonzept/#netze","title":"Netze","text":"<p>Die Netzwerkanbindung der Serverschr\u00e4nke im Maschinensaal und der zentralen Switche wird von der Abteilung \"eScience\" in Zusammenarbeit mit der Abteilung \"Netze und Kommunikationsdienste\" (Netzwerkabteilung) im RZ durchgef\u00fchrt. Diese Anbindung erlaubt eine Administration der Knoten in den Schr\u00e4nken von festgelegten IP-Adressen aus, die nur in R\u00e4umen der Universit\u00e4t Freiburg sowie \u00fcber VPN-Verbindungen zugewiesen werden.</p> <p>Die internen Uni-Netzwerke f\u00fcr das bwForCluster NEMO, die VFUs, das ATLAS-Cluster und die Isilon sind voneinander getrennt und lassen nur Zugriff von zum Betrieb notwendigen Netzen zu. Welche dies im einzelnen sind, m\u00fcssen vom jeweiligen Dienst erfragt werden.</p> <p>Das bwForCluster NEMO\u00a0verwendet folgende Netze:</p> <pre><code>10.16.0.0/16          NEMO: Rechenknoten, Server und Parallelspeicher\n                            Login- und Vis-Knoten \u00fcber interne Netzwerkschnittstelle\n132.230.222.0/24      NEMO: Login- und Visualisierungsknoten\n10.17.0.0/16          NEMO: CMS-VFU\n10.18.0.0/16          NEMO: ATLAS-VFU\n10.20.0.0/21          NEMO: NEMO-VFU (unused)\n10.20.8.0/21          NEMO: NEMO-VFU (unused)\n10.20.16.0/21         NEMO: NEMO-VFU (unused)\n10.20.24.0/21         NEMO: NEMO-VFU (unused)\n10.20.32.0/21         NEMO: NEMO-VFU (unused)\n10.20.40.0/21         NEMO: ATLAS-TEST-VFU\n</code></pre> <p>Obige Netze sind jeweils voneinander getrennt. Lediglich die ATLAS-VFU und ATLAS-TEST-VFU k\u00f6nnen zus\u00e4tzlich auf das NEMO-Netz <code>10.16.0.0/16</code> zugreifen. Das Cluster kann ansonsten nur \u00fcber die \u00f6ffentliche IP-Adressen der Login- und Vis-Knoten erreicht werden. Die Rechenknoten sind mit mindestens 1 GbE versorgt. Server, die Dienste anbieten, sind mit mindestens zwei Anschl\u00fcssen mit 10 GbE \u00fcber das Link Aggregation Control Protocol (LACP) an zwei Top-Level-Switche angebunden.<sup>18</sup> Zus\u00e4tzlich sind alle Rechenknoten mit dem Hochgeschwindigkeitsnetzwerk \"Omni-Path\" mit 100 Gbit/s untereinander und dem wissenschaftlichen Parallelspeicher verbunden.<sup>19</sup></p>"},{"location":"betriebskonzept/#zugang-zur-ressource","title":"Zugang zur Ressource","text":"<p>Zugang zum bwForCluster NEMO\u00a0haben lediglich registrierte Forscher*innen. Antragsberechtigt sind nur Wissenschaftler*innen aus Baden-W\u00fcrttemberg. Die genauen Zugangskriterien und die einzelnen Schritte der Registrierungsprozedur sind im bwHPC-Wiki beschreiben.<sup>20</sup> F\u00fcr das bwForCluster NEMO\u00a0muss von dem/der Wissenschaftler*in ein separates Dienst-Passwort angelegt werden.</p> <p>Das Auslaufen und die Invalidierung von Accounts regelt jede Universit\u00e4t selbst. Der Nutzer hat danach keinen Zugriff mehr auf die Ressourcen. Die Daten der Nutzer*innen verbleiben jedoch so lange auf dem Cluster, bis die Ressource abgeschaltet wird oder die Anfrage einer berechtigten Person erfolgt. Es gibt derzeit keine festen Regeln diesbez\u00fcglich, so dass diese Frage einer genaueren Ausarbeitung Bedarf. F\u00fcr das Nachfolgecluster, das voraussichtlich im Jahr 2022 in Betrieb gehen wird, wird eine L\u00f6sung erarbeitet. Die Universit\u00e4t stellt hierzu die folgenden Ordnungen zur Verf\u00fcgung:</p> <ul> <li>Verwaltungs- und Benutzungsordnung (VBO).<sup>21</sup></li> <li>Benutzungsordnung f\u00fcr die vom Rechenzentrum der     Albert-Ludwigs-Universit\u00e4t angebotenen Netzdienste: (NBO).<sup>22</sup></li> <li>Netzordnung f\u00fcr das Freiburger Universit\u00e4ts Netz: (NO).<sup>23</sup></li> </ul>"},{"location":"betriebskonzept/#kontingentierung","title":"Kontingentierung","text":"<p>Die Wissenschaftler*innen sind im Sinne der gemeinschaftlichen DFG-Beantragung Stakeholder des bwForClusters NEMO. Zus\u00e4tzlich gibt es Shareholder, die mit eigenen Mitteln Teile das Clusters mitfinanziert haben.<sup>24</sup> Diesen stehen zus\u00e4tzliche Anteile am Cluster zur Verf\u00fcgung. Die Regelung, wer wie viele Ressourcen des Clusters nutzen kann, wird \u00fcber einen \"Fairshare-Mechanismus\" geregelt.<sup>25</sup> Dieser bestimmt, wann ein Job eines/r Wissenschaftlers/in starten kann. Hierzu wird von einer Gruppe jeweils der Verbrauch der letzten drei Monate mit ihrem \"Share\" verglichen. Ist der Verbrauch h\u00f6her als der Share, der der Arbeitsgruppe zur Verf\u00fcgung steht, werden die Jobs niedriger priorisiert, ist er niedriger als der verf\u00fcgbare Share, werden die Jobs h\u00f6her priorisiert. Wissenschaftler*innen k\u00f6nnen aber mehr Ressourcen verwenden, als ihnen aufgrund ihres Shares zustehen w\u00fcrden. Sie werden dadurch in Zukunft nur schlechter in der Warteschlange priorisiert. Es gibt lediglich eine maximale Anzahl an Ressourcen, die ein/e Wissenschaftler*in gleichzeitig in die Warteschlange stellen kann.</p>"},{"location":"betriebskonzept/#administration","title":"Administration","text":"<p>Administrator*innen verf\u00fcgen \u00fcber erweiterte Rechte. Sie haben Zugriff auf alle Daten der Nutzer*innen, sofern diese nicht zus\u00e4tzlich verschl\u00fcsselt werden. Der administrative Zugang wird bei Bedarf manuell gew\u00e4hrt und wird bei Ausscheiden, beziehungsweise wenn die Rechte nicht mehr ben\u00f6tigt werden, manuell entzogen. Derzeit wird ein Protokoll f\u00fcr die Administration entwickelt, das diesen Aspekt regelt. Die Einf\u00fchrung des Protokolls zum Ein- beziehungsweise Austritt von Administrator*innen ist f\u00fcr den Start des bwForClusters NEMO2 2022 geplant.</p>"},{"location":"betriebskonzept/#monitoring_1","title":"Monitoring","text":"<p>Das Monitoring \u00fcberwacht den dauerhaften Betrieb mit Verfolgung der Ziele Verf\u00fcgbarkeit, Vertraulichkeit und Integrit\u00e4t der Daten. Beim Monitoring werden Schr\u00e4nke, Infrastrukturkomponenten wie Netzwerk, Speichersysteme, Server und Rechenknoten \u00fcberwacht. Neben der \u00dcberwachung der Hardware wird die Temperatur, Stromaufnahme und zus\u00e4tzlich bei Schr\u00e4nken die Luftfeuchtigkeit kontrolliert. Die Nachverfolgung des Netzwerks findet in der Netzwerkabteilung und bei Schr\u00e4nken in der Abteilung \"Allgemeiner Betrieb\" statt. Strom und K\u00fchlung werden zudem vom \"Technischen Geb\u00e4ugemanagement\" (TGM) \u00fcberwacht. Zus\u00e4tzlich protokolliert der Monitoring-Server des Clusters mit Hilfe von Zabbix Hardwaredaten wie Temperatur und Defekte auf Knotenebene und schl\u00e4gt beim \u00dcberschreiten von Grenzwerten per Mail Alarm.<sup>26</sup> Zabbix \u00fcberpr\u00fcft laufend, ob die Dienste, die auf den Servern laufen m\u00fcssen, noch aktiv sind. Es wird allerdings nicht gepr\u00fcft, ob die Dienste noch korrekt funktionieren.</p> <p>Au\u00dferdem werden Hardware- sowie Softwareprobleme, Login- und Zugriffsversuche \u00fcber <code>rsyslog</code> lokal auf der SSD und f\u00fcr die von den Wissenschaftler*innen erreichbaren Knoten wie Login-, Vis- und Rechenknoten zus\u00e4tzlich auf dem Monitoringserver in Dateien gespeichert.</p> <p>Der Speicherverbrauch im parallelen Dateisystem und den Home-Verzeichnissen wird mittels Quotas auf Nutzerebene durchgesetzt. Die Auslastung wird jeweils von den zust\u00e4ndigen Betreibern ermittelt. Bei Isilon ist das die Abteilung \"Virtualisierung und Speichersysteme\", beim BeeGFS machen das die Administrator*innen des bwForClusters NEMO. \"Workspaces\" auf dem parallelen Wissenschaftsspeicher BeeGFS haben eine Laufzeit von 100 Tagen und m\u00fcssen von den Wissenschaftler*innen mit einem Kommando manuell verl\u00e4ngert werden. Erfolgt das nicht, werden die Daten endg\u00fcltig nach einer Wartezeit von sieben Tagen gel\u00f6scht.</p>"},{"location":"betriebskonzept/#verantwortlichkeiten","title":"Verantwortlichkeiten","text":"<p>Die Verantwortung f\u00fcr den Betrieb des bwForClusters NEMO\u00a0liegt bei dem/der Leiter*in der Abteilung eScience. Diese/r berichtet der/dem Leiter*in des Rechenzentrums der Universit\u00e4t Freiburg.</p>"},{"location":"betriebskonzept/#maschinensaal-ii-msii","title":"Maschinensaal II (MSII)","text":"<p>Der MSII sowie die dar\u00fcber bereitgestellten Schr\u00e4nke werden von der Abteilung \"Allgemeiner Betrieb\" verantwortet. Das operative Gesch\u00e4ft sowie die organisatorischen Schnittstellen innerhalb des RZ sowie zu Nutzer*innen, die Ressourcen im Maschinensaal betreiben, werden in der \"Maschinensaalbenutzungsordnung\"<sup>27</sup> f\u00fcr den Maschinensaal beschrieben. Die Nutzung der Server-Schr\u00e4nke wird im Dienstkatalog \"Machine-Hosting\"<sup>28</sup> spezifiziert. Die Maschinensaalbenutzungsordnung bestimmt ebenfalls den physikalischen Zugriff der Administrator*innen des Clusters auf die Schr\u00e4nke und die darin eingebauten Maschinen.</p>"},{"location":"betriebskonzept/#referenzen","title":"Referenzen","text":"<ol> <li> <p>Hierzu entsteht derzeit das Dokument \"Compute-Forschungsinfrastrukturen: HPC\".\u00a0\u21a9</p> </li> <li> <p>BAUER, Jonathan, Dirk von SUCHODOLETZ, Jeannette VOLLMER und Helena RASCHE, 2019. Game of Templates: Deploying and (re-)using Virtualized Research Environments in High-Performance and High-Throughput Computing. In: Michael JANCZYK, Dirk von SUCHODOLETZ und Bernd WIEBELT (Hrsg.), Proceedings of the 5<sup>th</sup> bwHPC Symposium: HPC Activities in Baden-W\u00fcrttemberg. Freiburg, September 2018. TLP, T\u00fcbingen. 2019. S.\u00a0245-262\u00a0\u21a9</p> </li> <li> <p>SUCHODOLETZ, Dirk von, Jonathan BAUER, Oleg ZHARKOV, Susanne MOCKEN und Bj\u00f6rn GR\u00dcNING, 2020. Lessons learned from Virtualized Research Environments in today's scientific compute infrastructures. In: E-Science-Tage 2019: Data to Knowledge. Heidelberg: heiBOOKS. M\u00e4rz 2020. S.\u00a088-81. ISBN\u00a0978-3-948083-14-4 \u21a9</p> </li> <li> <p>SUCHODOLETZ, Dirk von und Jonathan BAUER, 2020. ViCE - Creating Uniform Approach to Large-Scale Research Infrastructures. In: E-Science-Tage 2019: Data to Knowledge. Heidelberg: heiBOOKS. M\u00e4rz 2020. S.\u00a0218-222. ISBN\u00a0978-3-948083-14-4 \u21a9</p> </li> <li> <p>MEIER, Konrad, Bj\u00f6rn GR\u00dcNING, Clemens BLANK, Michael JANCZYK und Dirk von SUCHODOLETZ, 2017. Virtualisierte wissenschaftliche Forschungsumgebungen und die zuk\u00fcnftige Rolle der Rechenzentren. In: 10. DFN-Forum Kommunikationstechnologien, 30.-31. Mai 2017, Berlin, Gesellschaft f\u00fcr Informatik eV (GI). 2017. S.\u00a0145-154\u00a0\u21a9</p> </li> <li> <p>MEIER, Konrad, 2017. Infrastrukturkonzepte f\u00fcr virtualisierte wissenschaftliche Forschungsumgebungen. phdthesis. Albert-Ludwigs-Universit\u00e4t Freiburg im Breisgau\u00a0\u21a9</p> </li> <li> <p>ESCIENCE TEAM, 2016. Cluster Betrieb: High Performance Computing [online]. techreport. Rechenzentrum der Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.rz.uni-freiburg.de/inhalt/dokumente/pdfs/dienstbeschreibung-hpc \u21a9</p> </li> <li> <p>Die aktuelle Hardware des bwForClusters NEMO\u00a0im zentralen Wiki dokumentiert: https://wiki.bwhpc.de/e/BwForCluster_NEMO_Hardware_and_Architecture#Compute_and_Special_Purpose_Nodes, besucht am 19.04.2021.\u00a0\u21a9</p> </li> <li> <p>Der Zugriff ist auf die IPv4-Prefixe des Belw\u00fc-Netzes beschr\u00e4nkt: https://bgpview.io/asn/553, besucht am 16.04.2021.\u00a0\u21a9</p> </li> <li> <p>Webseite Infoblox: https://www.infoblox.com/, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Derzeit wird CentOS7 als Betriebssystem eingesetzt. Das Nachfolgecluster wird RHEL8 oder ein bin\u00e4rkompatibles Derivat einsetzen.\u00a0\u21a9</p> </li> <li> <p>BAUER, Jonathan, Manuel MESSNER, Michael JANCZYK, Dirk von SUCHODOLETZ, Bernd WIEBELT und Helena RASCHE, 2019. A Sorting Hat For Clusters: Dynamic Provisioning of Compute Nodes for Colocated Large Scale Computational Research Infrastructures. In: Michael JANCZYK, Dirk von SUCHODOLETZ und Bernd WIEBELT (Hrsg.), Proceedings of the 5<sup>th</sup> bwHPC Symposium: HPC Activities in Baden-W\u00fcrttemberg. Freiburg, September 2018. TLP, T\u00fcbingen. 2019. S.\u00a0217-229\u00a0\u21a9</p> </li> <li> <p>STORAGE UND VIRTUALISIERUNGSGRUPPE, 2019. Speichersysteme f\u00fcr die Universit\u00e4t [online]. techreport. Rechenzentrum der Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.rz.uni-freiburg.de/inhalt/dokumente/pdfs/speichersysteme \u21a9</p> </li> <li> <p>Webseite zum Parallelspeicher BeeGFS: https://www.beegfs.io/, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Die Dokumente zu bwSFS werden derzeit noch erarbeitet. Diese werden nachgereicht.\u00a0\u21a9</p> </li> <li> <p>Webseite von ATLAS-BFG: https://www.hpc.uni-freiburg.de/atlas-bfg, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Github-Repo zu Workspaces: https://github.com/holgerBerger/hpc-workspace, besucht am 19.04.2021\u00a0\u21a9</p> </li> <li> <p>Wiki-Eintrag zu LACP: https://de.wikipedia.org/wiki/Link_Aggregation, besucht am 19.02.2021.\u00a0\u21a9</p> </li> <li> <p>Eintrag zu Omni-Path: https://de.wikipedia.org/wiki/Intel_Omni-Path, besucht am 19.02.2021.\u00a0\u21a9</p> </li> <li> <p>Registrierungsprozedur im Wiki: https://wiki.bwhpc.de/e/BwForCluster_User_Access, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>UNIVERSIT\u00c4T FREIBURG, 1981. Verwaltungs- und Benutzungsordnung: (VBO) [online]. techreport. Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.hpc.uni-freiburg.de/content/legalstuff/vbo.pdf \u21a9</p> </li> <li> <p>UNIVERSIT\u00c4T FREIBURG, 1996. Benutzungsordnung f\u00fcr die vom Rechenzentrum der Albert-Ludwigs-Universit\u00e4t angebotenen Netzdienste: (NBO) [online]. techreport. Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.hpc.uni-freiburg.de/content/legalstuff/nbo.pdf \u21a9</p> </li> <li> <p>UNIVERSIT\u00c4T FREIBURG, 1996. Netzordnung f\u00fcr das Freiburger Universit\u00e4ts Netz: (NO) [online]. techreport. Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.hpc.uni-freiburg.de/content/legalstuff/no.pdf \u21a9</p> </li> <li> <p>SUCHODOLETZ, Dirk von, Stefan WESNER und Gerhard SCHNEIDER, 2016. \u00dcberlegungen zu laufenden Cluster-Erweiterungen in bwHPC. In: Dirk von SUCHODOLETZ, Janne Chr. SCHULZ, Jan LEENDERTSE, Hartmut HOTZEL und Martin WIMMER (Hrsg.), Kooperation von Rechenzentren: Governance und Steuerung - Organisation, Rechtsgrundlagen, Politik. De Gruyter. 2016. S.\u00a0331-342. ISBN\u00a0978-3-11-045888-6 \u21a9</p> </li> <li> <p>Erkl\u00e4rung des Fairshare-Mechanismus Anhand der Anleitung des Schedulers Moab: http://docs.adaptivecomputing.com/9-1-3/suite/help.htm#topics/moabWorkloadManager/fairness/fairnessoverview.html, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Zabbix Monitoring-L\u00f6sung: https://www.zabbix.com, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>SCHULZ, Janne Chr., Dirk von SUCHODOLETZ, Ulrich GEHRING, Willibald MEYER und Jan LEENDERTSE, 2020. Maschinensaalbenutzungsordnung des Rechenzentrums der Universit\u00e4t Freiburg: Richtlinien f\u00fcr das Hosting und Housing von Hardware in den R\u00e4umen desRechenzentrums der Universit\u00e4t Freiburg [online]. techreport. Rechenzentrum der Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.rz.uni-freiburg.de/inhalt/dokumente/pdfs/msbo \u21a9</p> </li> <li> <p>SUCHODOLETZ, Dirk von, Ulrich GEHRING und Jan LEENDERTSE, 2020. Machine-Hosting: Bereitstellung von Rackspace in den Maschinens\u00e4len des RZ. externe Version [online]. techreport. Rechenzentrum der Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.rz.uni-freiburg.de/inhalt/dokumente/pdfs/dienstbeschr-machine-hosting \u21a9</p> </li> </ol>"},{"location":"bwcloud-migration/","title":"How to migrate your old bwCloud Freiburg images to the new bwCloud","text":"<p>A service of the bwForCluster NEMO.</p> <p>DISCLAIMER</p> <p>This in an unofficial migration guide. We do not guarantee for broken images or if the guide does not work as described.</p>"},{"location":"bwcloud-migration/#community-migration-guide","title":"Community Migration Guide","text":"<p>This guide is only for users of the University of Freiburg who have bwCloud images in the old Freiburg region and want to migrate them to the new bwCloud. If you want to contribute, fork the repository and create a pull request with your changes.</p>"},{"location":"bwcloud-migration/#first-configuration-steps","title":"First Configuration Steps","text":"<p>First you need to instal the command line interface tools and set up credentials for the old bwCloud.</p> <p>Follow these steps:</p> <ol> <li>First install <code>python-openstackclient</code> CLI, e.g: <pre><code>$ pip install python-openstackclient --user\n</code></pre> Some distributions provide packages that you can check first. Windows users might try to use Windows Subsystem for Linux or install Linux in VirtualBox, etc.</li> <li>Create a credentials file for the old bwCloud instance, e.g.: <code>bwcloud-old-creds.sh</code> Copy the contents of the following code window and replace <code>&lt;RZ_ID&gt;</code> with your university ID, e.g. the one you use for myLogin or myAccount. Change your project name if necessary. <pre><code>#!/usr/bin/env bash\nexport OS_AUTH_URL=https://idm01.bw-cloud.org:5000/v3\nexport OS_USERNAME=\"&lt;RZ_ID&gt;@uni-freiburg.de\"\n# change to old group project if necessary, e.g. freiburg_mygroup\nexport OS_PROJECT_NAME=\"Projekt_$OS_USERNAME\"\nunset OS_PROJECT_ID\nexport OS_USER_DOMAIN_NAME=\"Default\"\nif [ -z \"$OS_USER_DOMAIN_NAME\" ]; then unset OS_USER_DOMAIN_NAME; fi\nexport OS_PROJECT_DOMAIN_ID=\"default\"\nif [ -z \"$OS_PROJECT_DOMAIN_ID\" ]; then unset OS_PROJECT_DOMAIN_ID; fi\nunset OS_TENANT_ID\nunset OS_TENANT_NAME\necho \"Please enter your OpenStack Password for project $OS_PROJECT_NAME as user $OS_USERNAME: \"\nread -sr OS_PASSWORD_INPUT\nexport OS_PASSWORD=$OS_PASSWORD_INPUT\nexport OS_REGION_NAME=\"Freiburg\"\nif [ -z \"$OS_REGION_NAME\" ]; then unset OS_REGION_NAME; fi\nexport OS_INTERFACE=public\nexport OS_IDENTITY_API_VERSION=3\n</code></pre></li> </ol>"},{"location":"bwcloud-migration/#migrate-images","title":"Migrate Images","text":"<p>To migrate images, please follow these steps:</p> <ol> <li>Open a shell like <code>bash</code> or if you use a inkompatible shell like fish, start <code>bash</code>.</li> <li>Source your old bwCloud credentials. You will be prompted to enter your old bwCloud password. If you do not remember it, bwCloud support will have to generate a new one for you. <pre><code>$ source bwcloud-old-creds.sh\nPlease enter your OpenStack Password for project Projekt_&lt;RZ_ID&gt;@uni-freiburg.de as user &lt;RZ_ID&gt;@uni-freiburg.de: </code></pre></li> <li>Run <code>openstack server list</code>. You should see your images or the images from your group project. Copy the ID of the image you want to download, e.g. <code>7fd1037e-b9fa-464b-9704-0dd60461d83a</code>.</li> <li>Check if there is a snapshot for this image that you can download. To check this, use this ID to get the ID of the snapshot: <pre><code>$ openstack image list --shared | grep 7fd1037e-b9fa-464b-9704-0dd60461d83a\n| 3e51e17a-c04d-345a-8712-a13f3b8fb99b | 7fd1037e-b9fa-464b-9704-0dd60461d83a-snapshot-2022-03-11-19-40-06 | active |\n</code></pre> If there is no snapshot you can generate one yourself: <pre><code>$ openstack server image create --name 7fd1037e-b9fa-464b-9704-0dd60461d83a-snapshot-$(date -I) 7fd1037e-b9fa-464b-9704-0dd60461d83a\n</code></pre></li> <li>Use the snapshot ID for your download: <pre><code>$ glance image-download 3e51e17a-c04d-345a-8712-a13f3b8fb99b --file myimage.img --progress\n</code></pre></li> <li>Once your image is downloaded, visit https://portal.bw-cloud.org/project/images and select \"Compute -&gt; Images\":  If you want to use the CLI, go to section Upload Image through CLI.</li> <li>Configure your image and upload it. The minimum settings for hard disk and RAM are optional. Select the visibility Private!</li> </ol> <p>Attention</p> <p>If you don't choose the visibility \"Private\", others can use your image as base image for their services.</p> <p> 8. You can start a new instance with this image. Many other OpenStack settings need to be reconfigured, e.g. \"Security Groups\". This is not covered in this guide.</p>"},{"location":"bwcloud-migration/#migrate-volumes","title":"Migrate Volumes","text":"<p>To migrate volumes, please follow these steps:</p> <ol> <li>Open a shell like <code>bash</code> or if you use a inkompatible shell like fish, start <code>bash</code>.</li> <li>Source your old bwCloud credentials. You will be prompted to enter your old bwCloud password. If you do not remember it, bwCloud support will have to generate a new one for you. <pre><code>$ source bwcloud-old-creds.sh\nPlease enter your OpenStack Password for project Projekt_&lt;RZ_ID&gt;@uni-freiburg.de as user &lt;RZ_ID&gt;@uni-freiburg.de: </code></pre></li> <li>Run <code>openstack volume list</code>. You should see your volumes or the volumes from your group project. Copy the ID of the volume you want to download, e.g. <code>da832458-2b9a-144b-2904-0dd604d261da</code>.</li> <li>Create a new image from this volume: <pre><code>$ openstack image create --volume da832458-2b9a-144b-2904-0dd604d261da --force newimagename\n</code></pre> If you have errors running this command, see Troubleshooting for a solution.</li> <li>Check if the volume image is already created. <pre><code>$ openstack image list | grep newimagename\n| 93da1233-bfee-453b-9c1d-59aa45da20c7 | newimagename                                                      | active |\n</code></pre></li> <li>Use the new image ID for your download: <pre><code>$ glance image-download 93da1233-bfee-453b-9c1d-59aa45da20c7 --file myvolume.img --progress\n</code></pre></li> <li>Upload your image to OpenStack (see steps 6-8 in section Migrate Images or Upload Image through CLI.</li> <li>Once your image is uploaded, you can create a volume from it. Do this either in the GUI or use the CLI. For the GUI, visit https://portal.bw-cloud.org/project/images and select \"Compute -&gt; Images\". Select \"Create Volume\" from the menu.  For the CLI, you must first set up your credentials. To do this, follow steps 1-4 from the section Upload Image through CLI. Then check the ID of your image with <code>openstack image list</code>. Next, check the size of this image: <pre><code>$ openstack image show --human-readable 991346f0-7780-19f3-34b1-c854c45105da\n</code></pre> Unfortunately, the sizes are displayed in different units, so <code>openstack image show</code> shows the size in GB, but GiB is used when creating (e.g. 12.9GB ~ 12GiB). Now use the image ID to create a volume: <pre><code>$ openstack volume create --image 991346f0-7780-19f3-34b1-c854c45105da --size 12 myvolume # change size\n</code></pre></li> </ol>"},{"location":"bwcloud-migration/#upload-image-through-cli","title":"Upload Image through CLI","text":"<p>If uploading via the graphical user interface does not work for some reason, you can try it via the command line interface. First, perform steps 1-5 in section Migrate Images or steps 1-6 in section Migrate Volumes.</p> <p>Then, follow these steps:</p> <ol> <li>Login to bwCloud: https://portal.bw-cloud.org/identity/application_credentials/. Select \"Identity -&gt; Application Secrets\". </li> <li>Select a name and set a strong secret. </li> <li>Download <code>openrc</code> file.</li> <li>Open a new bash window and source the credentials: <pre><code>$ source app-cred-CLI-openrc.sh\n</code></pre></li> <li>Create/Upload image to new bwCloud: <pre><code>$ openstack image create --file myimage.img --private myimage\n</code></pre> Check status with <code>openstack image list</code>.</li> </ol>"},{"location":"bwcloud-migration/#troubleshooting","title":"Troubleshooting","text":"<p>If you get an error while running step 2 in the guide \"Migrate Volumes\", you can try to downgrade your tools. One error which is pretty common is this: <pre><code>TypeError: upload_to_image() got an unexpected keyword argument 'visibility'\n</code></pre></p> <p>This version numbers worked after some trial and error: <pre><code>$ pip install python-openstackclient==3.18 --user\n$ pip install python-cinderclient==5 --user\n</code></pre></p> <p>To update your tools back to the current version, run: <pre><code>$ pip install python-openstackclient python-cinderclient --user --upgrade\n</code></pre></p> <p>You can also patch the tool locally:<sup>1</sup> <pre><code>$ sed -Ei \"/kwargs.get\\\\('visibility'|protected=True/s/^/#/\" ~/.local/lib/python*/site-packages/openstackclient/image/v2/image.py\n</code></pre></p> <ol> <li> <p>See https://storyboard.openstack.org/#!/story/2009287 for problem description, visited 18.03.2022.\u00a0\u21a9</p> </li> </ol>"},{"location":"toms/","title":"Technisch Organisatorische Ma\u00dfnahmen","text":"G\u00fcltig ab: Version: 0.4.1 Datum: 21.06.2021 <p>TLP:AMBER</p> <p>Limited disclosure, restricted to participants' organizations. Distribution outside this audience requires written permission from the originator.</p> Version Datum Autor*innen \u00c4nderungen 0.4.1 21.06.2021 MJ Buchstabendreher und Anf\u00fchrungszeichen korrigiert. eduPersonPrincipalName statt EPPN und eduPersonEntitlement statt Entitlement verwendet. 0.4.0 26.05.2021 MJ,JL Einleitung gel\u00f6scht. Text entspricht Passagen aus ADV-Vertragsentwurf. 0.3.0 04.05.2021 MJ,JL Einleitung besteht aus Textpassagen aus dem ADV-Vertragsentwurf von JL. Zus\u00e4tzliche Korrekturen von JL eingearbeitet. Fu\u00dfnoten vervollst\u00e4ndigt. 0.2.0 22.04.2021 MJ Kleinere Korrekturen, Anpassungen und Entfernen von Redundanzen. 0.1.0 20.04.2021 MJ Erster Entwurf basierend auf Version 0.3.2 des Betriebskonzepts NEMO."},{"location":"toms/#vertraulichkeit","title":"Vertraulichkeit","text":""},{"location":"toms/#zutrittskontrolle","title":"Zutrittskontrolle","text":"<p>Die Zutrittskontrolle ist \u00fcber die Maschinensaalbenutzungsordnung (MsBO) festgelegt<sup>1</sup>. Diese regelt folgende Aspekte:</p> <ul> <li>Zugang ist nur f\u00fcr berechtigte Personen mittels Transponder m\u00f6glich.</li> <li>Die Vergabe der Schl\u00fcssel und Transponder ist dokumentiert.</li> <li>MSII ist alarmgesichert gegen Zutritt unbefugter Personen.</li> <li>MSII verf\u00fcgt \u00fcber Rauchmelder.</li> <li>W\u00e4hrend der \u00d6ffnungszeiten ist Zutritt in MSII nur \u00fcber eine   Magnetkarte oder einen Schl\u00fcssel m\u00f6glich.</li> <li>Au\u00dferhalb der \u00d6ffnungszeiten wird das Rechenzentrum regelm\u00e4\u00dfig von   einem Sicherheitsdienst kontrolliert.</li> <li>Zutritt f\u00fcr Wartungen durch externe Parteien wird dokumentiert.</li> </ul>"},{"location":"toms/#zugangskontrolle","title":"Zugangskontrolle","text":"<p>Die Zugangskontrolle zum bwForCluster NEMO\u00a0erfolgt \u00fcber mehrere Stufen. Das genauen Verfahren ist im bwHPC-Wiki beschrieben<sup>2</sup>. Die genauen Ma\u00dfnahmen beinhalten:</p> <ul> <li>Wissenschaftler*innen m\u00fcssen von der Universit\u00e4t berechtigt sein,   die Ressource zu nutzen. Hierzu wird von den Universit\u00e4ten das   \"Entitlement\" <code>http://bwidm.de/entitlement/bwForCluster</code>   vergeben<sup>3</sup>.</li> <li>Wissenschaftler*innen m\u00fcssen einen Projektantrag stellen   (Rechenvorhaben) oder sich einem bestehendem Projekt zuordnen<sup>4</sup>.</li> <li>Wissenschaftler*innen m\u00fcssen sich beim Cluster registrieren, dazu   werden Daten beim jeweiligen Identity-Provider (IdP) abgefragt<sup>5</sup>.   Diese Daten k\u00f6nnen auch jederzeit von den Nutzer*innen abgefragt   werden<sup>6</sup>. Hierzu geh\u00f6ren:</li> <li>Name</li> <li>E-Mail-Adresse</li> <li><code>eduPersonPrincipalName</code> (EPPN)<sup>7</sup></li> <li>Berechtigungen \u00fcber \"Entitlements\" (<code>eduPersonEntitlement</code>).</li> <li>Eine Unix-Gruppe, falls diese vom IdP ausgeliefert wird.</li> <li>Der Zugang ist \u00fcber eine Firewall auf Belw\u00fc-Netze beschr\u00e4nkt<sup>8</sup>.</li> <li>Au\u00dferhalb dieser Netze ist der Zugriff nur \u00fcber Jump-Hosts     (beispielsweise Proxy-Jump) oder VPN m\u00f6glich.</li> <li>Wissenschaftler*innen haben Zugriff von au\u00dfen \u00fcber SSH mit   Nutzername und Dienst-Passwort beziehungsweise SSH-Schl\u00fcssel auf   Login- und Visualisierungsknoten.</li> <li>Zugang \u00fcber das Openstack-Dashboard \u00fcber HTTPS mit Nutzername und   Dienst-Passwort.</li> <li>Administrator*innen haben nur mit Nutzername und SSH-Schl\u00fcssel   Zugriff.</li> <li>Eine Zwei-Faktor-Authentifizierung wird derzeit ausgerollt.</li> <li>Der Zugang wird \u00fcber Log-Dateien lokal und im Monitoring-Server   protokolliert.</li> </ul>"},{"location":"toms/#zugriffskontrolle","title":"Zugriffskontrolle","text":"<p>Die Zugriffskontrolle erfolgt auf Ebene von Unix-Rechten und \"Access Control Lists\" (ACL). Folgende Regeln gelten:</p> <ul> <li>Wissenschaftler*innen haben nur auf ihre eigenen Daten Zugriff.   Diese Berechtigungen k\u00f6nnen selbst f\u00fcr weitere Nutzer*innen,   beispielsweise \u00fcber ACLs, erweitert werden.</li> <li>Administratoren haben auf alle Daten und Bereiche Zugriff, wenn sie   nicht von Client- oder Nutzerseite verschl\u00fcsselt werden.</li> <li>Externe Supportmitarbeiter haben nur Zugriff auf die von ihnen zu   wartenden Komponenten.</li> <li>Testsysteme werden nur ausgew\u00e4hlten Personengruppen zur Verf\u00fcgung   gestellt und beeintr\u00e4chtigen nicht den Produktivbetrieb.</li> <li>Zentrales Benutzer-/Berechtigungs-Management folgt dem   Need-to-have-Prinzip f\u00fcr Wissenschaftler*innen, externen Support,   Projektmitarbeiter*innen im bwHPC, Testnutzer*innen und   Administrator*innen.</li> <li>Die Wissenschafler*innen verlieren ihren Zugriff, sobald dieser von   der Universit\u00e4t entzogen wird beziehungsweise der Account nicht mehr   g\u00fcltig ist. Die Regeln, wann dies erfolgt, werden von den   Universit\u00e4ten festgelegt.</li> <li>Weitere zus\u00e4tzliche Rechte, beispielsweise Administratorrechte,   werden manuell entzogen. Derzeit wird ein Protokoll f\u00fcr die   Administration entwickelt, das diesen Aspekt regelt. Die Einf\u00fchrung   des Protokolls zum Ein- beziehungsweise Austritt von   Administrator*innen ist f\u00fcr den Start des Nachfolgeclusters 2022   geplant.</li> </ul>"},{"location":"toms/#trennungskontrolle","title":"Trennungskontrolle","text":"<p>Die Trennungskontrolle gew\u00e4hrleistet, dass zu unterschiedlichen Zwecken erhobene Daten getrennt verarbeitet werden k\u00f6nnen. Hierzu z\u00e4hlen folgende Ma\u00dfnahmen:</p> <ul> <li>Physikalische und logische Trennung von Diensten, die nicht   unmittelbar miteinander in Bezug stehen.</li> <li>Physikalische und logische Trennung von Diensten und Netzen, die   nicht aufeinander zugreifen m\u00fcssen.</li> </ul>"},{"location":"toms/#integritat","title":"Integrit\u00e4t","text":""},{"location":"toms/#weitergabekontrolle","title":"Weitergabekontrolle","text":"<p>Als Weitergabekontrolle werden Ma\u00dfnahmen bezeichnet, die ein unbefugtes Lesen, Kopieren, Ver\u00e4ndern oder Entfernen bei elektronischer \u00dcbertragung oder Transport verhindern. Das bwForCluster NEMO\u00a0ist nur \u00fcber folgende Protokolle und Wege erreichbar:</p> <ul> <li>Zugriff auf das Cluster ist auf das Belw\u00fc-Netz beschr\u00e4nkt.</li> <li>Au\u00dferhalb des Belw\u00fc-Netzes muss VPN oder ein Jump-Host im Belw\u00fc   verwendet werden.</li> <li>Zugriffe werden auf Serverseite protokolliert.</li> <li>Zugriff kann nur \u00fcber verschl\u00fcsselte Dienste wie SSH und HTTPS   erfolgen.</li> <li>Die lokale Festplatte der Rechenknoten wird beim Booten   verschl\u00fcsselt und kann nach Entfernen nicht ausgelesen werden.</li> <li>Die Platten im Parallelspeicher enthalten nur Teile von Bl\u00f6cken und   eine Rekonstruktion ist nur m\u00f6glich, wenn Teile entwendet werden,   aus denen Daten ausreichend vollst\u00e4ndig zusammengesetzt werden   k\u00f6nnen. Jedoch ist f\u00fcr das Nachfolgesystem evtl. eine   Verschl\u00fcsselung geplant.</li> </ul>"},{"location":"toms/#verfugbarkeit-belastbarkeit","title":"Verf\u00fcgbarkeit, Belastbarkeit","text":""},{"location":"toms/#verfugbarkeitskontrolle","title":"Verf\u00fcgbarkeitskontrolle","text":"<p>Zur Verf\u00fcgbarkeitskontrolle z\u00e4hlen Ma\u00dfnahmen, die eine zuf\u00e4llige Zerst\u00f6rung oder Verlust von Daten und die Nutzbarkeit der Rechenressourcen beschreiben. Das bwForCluster NEMO implementiert folgende Schutzma\u00dfnahmen:</p> <ul> <li>Feuer- und Rauchmeldeanlagen in MSII und Infrastrukturr\u00e4umen wie   K\u00fchlung und Strom.</li> <li>Redundante K\u00fchlung bis zur Abschaltung f\u00fcr Cluster-kritische Dienste   wie Parallelspeicher, HOME-Speicher und Server f\u00fcr Dienste.   Rechenknoten sind nicht gesch\u00fctzt, k\u00f6nnen aber nach Behebung der   St\u00f6rung sofort wieder hochgefahren werden. Da im Desasterfall der   Parallelspeicher und die Dienste vermutlich nicht ben\u00f6tigt werden,   k\u00f6nnen diese unter Umst\u00e4nden vorsichtshalber sicher herunter   gefahren werden.</li> <li>F\u00fcr Server und Speicher des bwForClusters NEMO\u00a0besteht   unterbrechungsfreie Stromversorgung sowie Notstromversorgung.</li> <li>Die Temperatur, Feuchtigkeit und Stromverbrauch der Maschinen und   der Datenschr\u00e4nke werden \u00fcberwacht.</li> <li>Das HOME-Verzeichnis der Wissenschaftler*innen ist georedundant   gespeichert und bietet automatische Snapshots<sup>9</sup>.</li> <li>Der Parallelspeicher ist mit RAID-6 abgesichert.</li> <li>Der Zugriff auf die Login- und Vis-Knoten ist durch eine Firewall   und Fail2ban gesichert. Der Zugriff auf das Cloud-Dashboard \u00fcber   eine Firewall abgesichert. Die restlichen Komponenten sind nur   Cluster-intern erreichbar. Ausf\u00e4lle durch Angriffe externer Parteien   k\u00f6nnen so minimiert werden.</li> <li>Der Zugriff auf das bwForCluster NEMO\u00a0ist nur Wissenschaftler*innen   aus baden-w\u00fcrttembergischen Universit\u00e4ten, wenigen   Administrator*innen und Support-Mitarbeitern erlaubt, was den   Angriffsvektor zus\u00e4tzlich verkleinert.</li> <li>Die Verf\u00fcgbarkeit des bwForClusters NEMO\u00a0wird \u00fcberwacht.</li> <li>Das Wiederanfahren des Systems kann nach \"Ausf\u00e4llen ohne   Datenverlust\" innerhalb weniger Stunden erfolgen.</li> </ul>"},{"location":"toms/#regelmaige-uberprufung-bewertung-evaluation","title":"Regelm\u00e4\u00dfige \u00dcberpr\u00fcfung, Bewertung, Evaluation","text":""},{"location":"toms/#datenschutz-und-informationssicherheits-management","title":"Datenschutz- und Informationssicherheits-Management","text":"<p>Die Universit\u00e4t Freiburg nimmt den Schutz der ihr anvertrauten personenbezogenen Daten sehr ernst und behandelt diese vertraulich und entsprechend der gesetzlichen Vorschriften. Neben den Regelungen der Europ\u00e4ischen Datenschutz-Grundverordnung (DSGVO) richtet sich die Verarbeitung personenbezogener Daten an der Universit\u00e4t nach dem Landesdatenschutzgesetz (LDSG) sowie den einschl\u00e4gigen Regelungen des Landeshochschulgesetzes (LHG).</p> <p>Die Datenschutzbeauftragte Person der Universit\u00e4t Freiburg kann unter der E-Mail-Adresse</p> <pre><code>datenschutzbeauftragter@uni-freiburg.de\n</code></pre> <p>sowie unter der Postadresse der Universit\u00e4t mit dem Zusatz \"Der Datenschutzbeauftragte\" erreicht werden. Allgemeinen Fragen zum Thema Datenschutz k\u00f6nnen an die E-Mail-Adresse</p> <pre><code>datenschutz@uni-freiburg.de\n</code></pre> <p>gerichtet werden.</p> <p>Dazu arbeitet die Universit\u00e4t weiterhin mit der Zentralen Datenschutzstelle der baden-w\u00fcrttembergischen Universit\u00e4ten (ZENDAS) zusammen.</p>"},{"location":"toms/#incident-response-management","title":"Incident-Response-Management","text":"<p>Das Incident-Response-Management unterst\u00fctzt bei der Reaktion auf Sicherheitsverletzungen. Hierzu z\u00e4hlen beim bwForCluster NEMO:</p> <ul> <li>Meldung von Sicherheitsvorf\u00e4llen beim Sicherheitsbeauftragten und   Datenschutzbeauftragten der Universit\u00e4t, bei den Projektpartnern im   bwHPC und dem DFNCert.</li> <li>Das DFNCert untersucht Angriffe durch externe Parteien.</li> </ul>"},{"location":"toms/#datenschutzfreundliche-voreinstellungen","title":"Datenschutzfreundliche Voreinstellungen","text":"<p>F\u00fcr die Registrierung beim bwForCluster NEMO\u00a0werden nur so viele personenbezogene Daten erhoben, wie f\u00fcr den Dienst notwendig sind, siehe Abschnitt Zugangskontrolle.</p>"},{"location":"toms/#referenzen","title":"Referenzen","text":"<ol> <li> <p>SCHULZ, Janne Chr., Dirk von SUCHODOLETZ, Ulrich GEHRING, Willibald MEYER und Jan LEENDERTSE, 2020. Maschinensaalbenutzungsordnung des Rechenzentrums der Universit\u00e4t Freiburg: Richtlinien f\u00fcr das Hosting und Housing von Hardware in den R\u00e4umen desRechenzentrums der Universit\u00e4t Freiburg [online]. techreport. Rechenzentrum der Universit\u00e4t Freiburg. Verf\u00fcgbar unter: https://www.rz.uni-freiburg.de/inhalt/dokumente/pdfs/msbo \u21a9</p> </li> <li> <p>Registrierungsprozedur im zentralen HPC-Wiki: https://wiki.bwhpc.de/e/BwForCluster_User_Access, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Beschreibung des Attributs <code>eduPersonEntitlement</code>: https://www.bwidm.de/attribute.php#Berechtigung, besucht am 04.05.2021.\u00a0\u21a9</p> </li> <li> <p>Hierzu werden an der \"Zentralen Antragsseite\" (ZAS) folgende Attribute abgefragt: https://www.bwidm.de/dienste.php, besucht am 04.05.2021.\u00a0\u21a9</p> </li> <li> <p>Siehe Dienst bwForCluster f\u00fcr genaue Beschreibung der abgefragten Daten: https://www.bwidm.de/dienste.php, besucht am 04.05.2021.\u00a0\u21a9</p> </li> <li> <p>Wissenschaftler*innen aus Baden-W\u00fcrttemberg k\u00f6nnen sich registrieren und danach ihre gespeicherten Daten auf der Registrierungsseite \u00fcberpr\u00fcfen: https://bwservices.uni-freiburg.de/user/index.xhtml, besucht am 20.04.2021.\u00a0\u21a9</p> </li> <li> <p>Beschreibung des Attributs <code>eduPersonPrincipalName</code>: https://www.bwidm.de/attribute.php#Principal%20Name, besucht am 04.05.2021.\u00a0\u21a9</p> </li> <li> <p>Der Zugriff ist auf die IPv4-Prefixe des Belw\u00fc-Netzes beschr\u00e4nkt: https://bgpview.io/asn/553, besucht am 16.04.2021.\u00a0\u21a9</p> </li> <li> <p>Snapshots sind regelm\u00e4\u00dfige Speicherst\u00e4nde des HOME-Verzeichnisses zum Zeitpunkt der Aufnahme.\u00a0\u21a9</p> </li> </ol>"},{"location":"gitlab/","title":"Gitlab Fast Recovery","text":"<p>This example describes a Gitlab installation on the bwCloud.</p>"},{"location":"gitlab/#prerequisites","title":"Prerequisites","text":"<p>Get a cloud vm with at least medium, better large flavor and an external IP address. Generate a DNS entry with a valid TLD to be able to get a certificate. Instances which will be only accessed within the university can use an internal IP address and can use intra.uni-freiburg.de for the DNS domain. Configure security group to allow SSH and HTTP(S). When using Letsencrypt HTTP needs to be available worldwide.</p>"},{"location":"gitlab/#optional-get-almalinux-and-rockylinux-on-clouds-with-centos-stream","title":"Optional get AlmaLinux and Rockylinux on Clouds with CentOS Stream","text":"<p>Use the CentOS Stream image and run the following as root. For Almalinux get migration tool first.</p> <p>Bash:</p> <pre><code>curl https://raw.githubusercontent.com/rocky-linux/rocky-tools/main/migrate2rocky/migrate2rocky.sh -o migrate2rocky.sh\nchmod +x migrate2rocky.sh\n./migrate2rocky.sh -r\nrm migrate2rocky.sh -f\nreboot\n</code></pre>"},{"location":"gitlab/#install-needed-packages","title":"Install needed Packages","text":"<p>Bash:</p> <pre><code>yum install -y curl policycoreutils openssh-server perl\n# firewalld optional, when vm security group is insufficient\nyum install -y postfix\nyum install -y firewalld # optional, when security groups configured\nsystemctl enable --now postfix.service\n</code></pre> <p>Configure firewall and postfix if needed and enable services.</p>"},{"location":"gitlab/#considerations-about-ssl","title":"Considerations about SSL","text":"<p>If you install a internal Gitlab instance, which can only be accessed within a internal and separate network, you can consider using HTTP without SSL. SSL only works for external domain names. Letsencrypt needs external IP and DNS entry. Uni Freiburg supports SSL with internal IP addresses and DNS intra.uni-freiburg.de.</p> <p>Most services like Gitlab runner and pages should work without SSL but should only used for testing, demo or within isolated networks.</p>"},{"location":"gitlab/#questions","title":"Questions","text":"<p>Will Letsencrypt work with internal IP addresses and intra.uni-freiburg.de?</p>"},{"location":"gitlab/#install-gitlab-omnibus","title":"Install Gitlab Omnibus","text":"<p>Bash:</p> <pre><code>curl -L \"https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh\" | sudo bash\nEXTERNAL_URL=\"https://gitlab.sub1.uni-freiburg.de\" yum install -y gitlab-ee\n</code></pre> <p>When your OS is not recognized you can try the following:</p> <pre><code>curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh -o script.rpm.sh\nchmod +x script.rpm.sh\nos=el dist=8 ./script.rpm.sh\nrm script.rpm.sh -f\n</code></pre> <p>Login name is <code>root</code> the password is stored in <code>/etc/gitlab/initial_root_password</code>. Please change within 24h.</p>"},{"location":"gitlab/#configure-gitlab-instance","title":"Configure Gitlab Instance","text":"<p>Gitlab is configured in file <code>/etc/gitlab/gitlab.rb</code> if not specified otherwise.</p> <p>If not specified during installation, change the name of your instance. <code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>external_url 'https://gitlab.sub1.uni-freiburg.de'\n</code></pre> <p>When using HTTPS set up Letsencrypt. For Uni Freiburg CA see Gitlab SSL Configuration.</p> <p><code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>letsencrypt['enable'] = true\nletsencrypt['contact_emails'] = ['my.name@rz.uni-freiburg'] # optional\n</code></pre> <p>Reconfigure Gitlab. Bash:</p> <pre><code>gitlab-ctl reconfigure\n</code></pre>"},{"location":"gitlab/#security-considerations","title":"Security considerations","text":"<p>After first loggin change the password for user <code>root</code>. Add a second factor. After registering you phone app, consider adding U2F devices.</p> <p>Go to \"Admin Area\", \"General\" and change following boxes in \"Sign-in restrictions\":</p> <ul> <li>check \"Enforce two-factor authentication\"</li> <li>check \"Enable admin mode\"</li> <li>uncheck \"Allow password authentication for Git over HTTP(S)\"</li> <li>uncheck \"Sign-up enabled\" if you do not want Gitlab instance local users</li> </ul> <p>In box \"Visibility and access controls\" change \"Enabled Git access protocols\" to \"Only SSH\".</p>"},{"location":"gitlab/#configure-access-though-external-services","title":"Configure Access though External Services","text":""},{"location":"gitlab/#onmiauth","title":"Onmiauth","text":"<ul> <li>Gitlab Documentation: Generic OpenID Connect</li> <li>Gitlab Documentation: Gitlab.com</li> <li>Gitlab Documentation: Github</li> </ul> <p>Omniauth allows Authentication through OpenID-Connect and Services like Giltab.com and Github.</p> <p>If you want to use Keycloak from bwSFS, Gitlab.com and Github, use this example for configuration</p> <pre><code>gitlab_rails['omniauth_enabled'] = true\ngitlab_rails['omniauth_allow_single_sign_on'] = ['openid_connect', 'gitlab', 'github']\ngitlab_rails['omniauth_auto_link_user'] = ['openid_connect', 'gitlab', 'github']\ngitlab_rails['omniauth_external_providers'] = ['openid_connect', 'gitlab', 'github']\ngitlab_rails['omniauth_providers'] = [\n{ 'name' =&gt; 'openid_connect',\n'label' =&gt; 'Keycloak RZ',\n'args' =&gt; {\n'name' =&gt; 'openid_connect',\n'scope' =&gt; ['openid','profile','email'],\n'response_type' =&gt; 'code',\n'issuer' =&gt; 'https://keycloak.sub2.uni-freiburg.de/auth/realms/rdm-services',\n'discovery' =&gt; true,\n'client_auth_method' =&gt; 'query',\n'uid_field' =&gt; 'sub',\n'send_scope_to_token_endpoint' =&gt; 'true',\n'client_options' =&gt; {\n'identifier' =&gt; '&lt;CLINET_ID&gt;',\n'secret' =&gt; '&lt;CLIENT_SECRET&gt;',\n'redirect_uri' =&gt; 'https://gitlab.sub1.uni-freiburg.de/users/auth/openid_connect/callback'\n}\n}\n},\n{\n\"name\" =&gt; \"gitlab\",\n\"app_id\" =&gt; \"&lt;APP_ID&gt;\",\n\"app_secret\" =&gt; \"&lt;APP_SECRET&gt;\",\n\"args\" =&gt; { \"scope\" =&gt; \"api\" }\n},\n{\n\"name\" =&gt; \"github\",\n\"app_id\" =&gt; \"&lt;APP_ID&gt;\",\n\"app_secret\" =&gt; \"&lt;APP_SECRET&gt;\",\n\"args\" =&gt; { \"scope\" =&gt; \"user:email\" }\n}\n]\n</code></pre> <p>For Keycloak connect you will need to get credentials for <code>client_options</code>. For Gitlab.com and Github connect <code>app_id</code> and <code>app_secret</code> have to be generated first. For Gitlab.com see this document, for Github refer to this document.</p>"},{"location":"gitlab/#ldap","title":"LDAP","text":"<ul> <li>Gitlab Documentation: LDAP</li> </ul> <p>Example for Uni Freiburg LDAP, add following lines to <code>/etc/gitlab/gitlab.rb</code>:</p> <p><code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>gitlab_rails['ldap_enabled'] = true\ngitlab_rails['prevent_ldap_sign_in'] = false\ngitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-'EOS'\nmain: # 'main' is the GitLab 'provider ID' of this LDAP server\nlabel: 'LDAP'\nhost: 'ldap.sub3.uni-freiburg.de'\nport: 389 # or 636\nuid: 'uid'\nencryption: 'start_tls' # \"start_tls\" or \"simple_tls\" or \"plain\"\nverify_certificates: true\nsmartcard_auth: false\nactive_directory: false\nallow_username_or_email_login: true\nlowercase_usernames: false\nblock_auto_created_users: false\nbase: 'dc=service1,dc=uni-freiburg,dc=de'\nuser_filter: ''\nattributes:\nusername: 'uid'\nemail: 'rufPreferredMail'\nname: 'cn'\nfirst_name: 'givenName'\nlast_name: 'sn'\nEOS\n</code></pre> <p>Add LDAP bind information to secrets file. Bash:</p> <pre><code>gitlab-rake gitlab:ldap:secret:edit EDITOR=vim\n</code></pre> <p>Add your bind information:</p> <pre><code>main:\nbind_dn: \"uid=admin,ou=system\"\npassword: \"&lt;PASSWORD&gt;\"\n</code></pre> <p>To get a verified SSL connection, it may be necessary to add the GEANT chain to trusted certs directory.</p> <p>Bash:</p> <pre><code>curl -Lo /etc/gitlab/trusted-certs/geant-chain.pem https://crt.sh/?d=2475254782\n</code></pre> <p>Reconfigure Gitlab. Bash:</p> <pre><code>gitlab-ctl reconfigure\n</code></pre> <p>Check LDAP configuration.</p> <pre><code>gitlab-rake gitlab:ldap:check\n</code></pre> <p>Alternavively:</p> <pre><code>echo | /opt/gitlab/embedded/bin/openssl s_client -connect ldap.sub3.uni-freiburg.de:389 -starttls ldap -showcerts\n#echo | /opt/gitlab/embedded/bin/openssl s_client -connect ldap.sub3.uni-freiburg.de:636 -showcerts\n</code></pre>"},{"location":"gitlab/#using-external-object-stores","title":"Using External Object Stores","text":"<ul> <li>Gitlab Documentation: Object Storage</li> </ul> <p>First generate one S3 storage bucket for each service you want to use and generate the access keys and secrets. In most cases you can configure S3 storage in the corresponding section of a service or you can use the special s3 storage block to configure most storage buckets in one place. For the sake of simplicity the following example uses the s3 storage block to configure most s3 buckets. If you don't want an object storage for a service, just add <code>false</code> instead of a bucket name.</p> <pre><code>gitlab_rails['object_store']['enabled'] = true\ngitlab_rails['object_store']['connection'] = {\n'provider' =&gt; 'AWS',\n'region' =&gt; '&lt;AWS_DEFAULT_REGION&gt;',\n'aws_access_key_id' =&gt; '&lt;AWS_ACCESS_KEY_ID&gt;',\n'aws_secret_access_key' =&gt; '&lt;AWS_SECRET_ACCESS_KEY&gt;',\n'host' =&gt; 's3.sub4.uni-freiburg.de',\n'aws_signature_version' =&gt; 2, # For creation of signed URLs. Set to 2 if provider does not support v4.\n'endpoint' =&gt; 'https://s3.sub4.uni-freiburg.de', # default: nil - Useful for S3 compliant services such as DigitalOcean Spaces\n'path_style' =&gt; false # false: Use 'host/bucket_name/object' instead of 'bucket_name.host/object'\n}\ngitlab_rails['object_store']['proxy_download'] = false\ngitlab_rails['object_store']['objects']['artifacts']['bucket'] = \"bucket-gitlab-artifacts\"\ngitlab_rails['object_store']['objects']['dependency_proxy']['bucket'] = false\ngitlab_rails['object_store']['objects']['external_diffs']['bucket'] = false\ngitlab_rails['object_store']['objects']['lfs']['bucket'] = \"bucket-gitlab-lfs\"\ngitlab_rails['object_store']['objects']['packages']['bucket'] = \"bucket-gitlab-packages\"\ngitlab_rails['object_store']['objects']['pages']['bucket'] = \"bucket-gitlab-pages\"\ngitlab_rails['object_store']['objects']['terraform_state']['bucket'] = false\ngitlab_rails['object_store']['objects']['uploads']['bucket'] = \"bucket-gitlab-uploads\"\n</code></pre> <p>If you want to use different secrets for each bucket use s3 configuration in each service. The following shows a s3 configuration for the Gitlab container registry. This bucket can't be configured in the above example yet (see Gitlab Doc) and has to be in the service section for container registry.</p> <pre><code>registry['storage'] = {\n's3' =&gt; {\n'accesskey' =&gt; '&lt;AWS_ACCESS_KEY_ID&gt;',\n'secretkey' =&gt; '&lt;AWS_SECRET_ACCESS_KEY&gt;',\n'bucket' =&gt; 'bucket-gitlab-registry',\n'region' =&gt; '&lt;AWS_DEFAULT_REGION&gt;',\n'regionendpoint' =&gt; 's3.sub4.uni-freiburg.de',\n'path_style' =&gt; false # (false) Use 'host/bucket_name/object' instead of 'bucket_name.host/object'\n},\n'redirect' =&gt; {\n'disable' =&gt; false\n}\n}\n</code></pre> <p>If you already have used file storage you can run the following to migrate to object storage.</p> <p>Pages:</p> <pre><code>gitlab-rake gitlab:pages:deployments:migrate_to_object_storage\n</code></pre> <p>LSF, Artifacts, Uploads, Packages:</p> <pre><code>gitlab-rake gitlab:lfs:migrate\ngitlab-rake gitlab:artifacts:migrate\ngitlab-rake gitlab:uploads:migrate:all\ngitlab-rake gitlab:packages:migrate\n</code></pre>"},{"location":"gitlab/#gitlab-runner","title":"Gitlab Runner","text":"<p>Gitlab runner are used for CI/CD and can be used for generating web sites for gitlab pages, etc.</p> <p>This section focuses on a separate VM for a shared runner, which can be used by all users. A runner can be one of these executors. For simplicity this documentation focuses on the docker executor.</p> <p>First create a new VM. Use a flavor with a virtual disk of at least 20GB. The docker containers can use a lot of space after some time. If you want to build containers with CI you will need temporary some GB of space during CI/CD.</p>"},{"location":"gitlab/#install-docker-engine","title":"Install Docker Engine","text":"<p>Gitlab Documentation: Install Docker</p> <p>Install dependencies and repo:</p> <pre><code>yum install -y yum-utils\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n</code></pre> <p>Install Docker Engine and containderd:</p> <pre><code>yum install -y docker-ce docker-ce-cli containerd.io\n</code></pre> <p>Enable Docker:</p> <pre><code>systemctl enable --now docker.service\n</code></pre>"},{"location":"gitlab/#install-gitlab-runner","title":"Install Gitlab Runner","text":"<p>Gitlab Documentation: Runner Installation</p> <p>Bash:</p> <pre><code>curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpcurl -L \"https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.rpm.sh\" | sudo bash\nyum install -y gitlab-runner\n</code></pre>"},{"location":"gitlab/#register-shared-docker-runner","title":"Register Shared Docker Runner","text":"<p>Gitlab Documentation: Runner Registration</p> <p>For a shared runner, as administrator get the \"registration token\" by visiting the \"Admin Area\" and select Overview and Runners in the menu.</p> <p>On your runner instance run <code>gitlab-runner register</code> and enter the following the following:</p> <pre><code>[root@gitlab-runner ~]# gitlab-runner register\nRuntime platform                                    arch=amd64 os=linux pid=11972 revision=de104fcd version=14.5.1\nRunning in system-mode.\n\nEnter the GitLab instance URL (for example, https://gitlab.com/):\nhttps://gitlab.sub1.uni-freiburg.de    # add your Gitlab instance\nEnter the registration token:\n&lt;TOKEN&gt;                                # copy token here\nEnter a description for the runner:\n[gitlab-runner.sub1.uni-freiburg.de]:  # add a name for your runner\nEnter tags for the runner (comma-separated):\ndocker                                 # add tags, e.g. executor\nRegistering runner... succeeded                     runner=abc123\nEnter an executor: virtualbox, docker-ssh, parallels, shell, ssh, docker+machine, docker-ssh+machine, kubernetes, custom, docker:\ndocker                                 #  add executor, here we use docker\nEnter the default Docker image (for example, ruby:2.6):\nubuntu:latest                          # name of the default docker image\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n</code></pre> <p>If you want to build and test containers like Singularity, you need to enable privileged docker execution. And while editing <code>/etc/gitlab-runner/config.toml</code> you can increase concurrency (<code>concurrent</code>) if needed.</p> <pre><code>/etc/gitlab-runner/config.toml:\n\n[runners.docker]\nprivileged = true\n</code></pre> <p>Restart Runner:</p> <pre><code>gitlab-runner restart\n</code></pre>"},{"location":"gitlab/#gitlab-pages","title":"Gitlab Pages","text":"<p>Gitlab Documentation: Gitlab Pages</p>"},{"location":"gitlab/#pages-running-on-the-same-server","title":"Pages Running on the Same Server","text":"<p>If you want to run pages on the same instance as Gitlab, you should add a wildcard DNS <code>A record</code>:</p> <pre><code>*.sub1.uni-freiburg.de. 1800 IN A    &lt;IP-ADDRESS-GITLAB&gt;\n</code></pre> <p>If you are using <code>https://gitlab.sub1.uni-freiburg.de</code> for your Gitlab instance, the domain for pages should be <code>http://&lt;PAGES-SUBDOMAIN&gt;.sub1.uni-freiburg.de</code>:</p> <pre><code>pages_external_url \"http://pages.sub1.uni-freiburg.de\" # not a subdomain of external_url\n</code></pre>"},{"location":"gitlab/#custom-domains","title":"Custom Domains","text":"<p>If you want to support custom domains configure a second IP. You can use a configuration for same or separate Pages server. If you use only one server you'll need to configure a second IP.</p> <p><code>A records</code>:</p> <pre><code>gitlab.sub1.uni-freiburg.de. 1800 IN A   &lt;IP-ADDRESS-GITLAB&gt;\n*.sub1.uni-freiburg.de.      1800 IN A   &lt;IP-ADDRESS-PAGES&gt;\n</code></pre> <p>In your config add following lines:</p> <pre><code>pages_external_url \"http://pages.sub1.uni-freiburg.de\" # not a subdomain of external_url\nnginx['listen_addresses'] = ['&lt;IP-ADDRESS-GITLAB&gt;'] # The primary IP of the GitLab instance\ngitlab_pages['enable'] = false\ngitlab_pages['external_http'] = ['&lt;IP-ADDRESS-PAGES&gt;:80'] # The secondary IPs for the GitLab Pages daemon\n</code></pre> <p>Reconfigure Gitlab:</p> <pre><code>gitlab-ctl reconfigure\n</code></pre>"},{"location":"gitlab/#pages-running-on-a-separate-server","title":"Pages Running on a Separate Server","text":"<p>If you want to run a separate Pages instance on a different server than your Gitlab instance, please follow the next steps.</p>"},{"location":"gitlab/#changes-on-the-gitlab-server","title":"Changes on the Gitlab Server","text":"<p>First, create a backup of the secrets file on the GitLab server:</p> <pre><code>cp /etc/gitlab/gitlab-secrets.json /etc/gitlab/gitlab-secrets.json-$( date -I )\n</code></pre> <p>Add a wildcard DNS <code>A record</code> for the Gitlab Pages domain:</p> <pre><code>*.external1.uni-freiburg.de. 1800 IN A    &lt;IP-ADDRESS-PAGES&gt;\n</code></pre> <p>The domain for Pages should be <code>http://&lt;PAGES-EXTERNAL&gt;.external1.uni-freiburg.de</code>:</p> <p>Change the following in your config:</p> <pre><code>pages_external_url \"http://pages.external1.uni-freiburg.de\"\ngitlab_pages['enable'] = false\ngitlab_pages['external_http'] = ['&lt;IP-ADDRESS-PAGES&gt;']\npages_nginx['enable'] = false\n</code></pre> <p>Reconfigure Gitlab:</p> <pre><code>gitlab-ctl reconfigure\n</code></pre>"},{"location":"gitlab/#changes-on-the-pages-server","title":"Changes on the Pages Server","text":"<p>First you need to install a second Gitlab instance and do some basic configuration from step Configure Gitlab Instance. When the Pages server is ready, proceed with the configuration.</p> <p>Create a backup of the secrets file on the GitLab server:</p> <pre><code>cp /etc/gitlab/gitlab-secrets.json /etc/gitlab/gitlab-secrets.json-$( date -I )\n\nCopy `/etc/gitlab/gitlab-secrets.json` from the Gitlab server to the Pages server.\n</code></pre> <p>Add the following to <code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>roles ['pages_role']\npages_external_url \"http://pages.external1.uni-freiburg.de\"\ngitlab_pages['gitlab_server'] = 'https://gitlab.sub1.uni-freiburg.de'\n</code></pre> <p>Reconfigure Gitlab:</p> <pre><code>gitlab-ctl reconfigure\n</code></pre>"},{"location":"gitlab/#using-wildcard-certificates","title":"Using Wildcard Certificates","text":"<p>If you want to use wildcard certificates for pages, copy your certificate and key to <code>/etc/gitlab/ssl</code>.</p> <p>Example:</p> <pre><code>/etc/gitlab/ssl/pages.sub1.uni-freiburg.de.crt\n/etc/gitlab/ssl/pages.sub1.uni-freiburg.de.io.key\n</code></pre> <p>If you used a different name, change the path in the config. <code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>pages_nginx['ssl_certificate'] = \"/etc/gitlab/ssl/pages-nginx.crt\"\npages_nginx['ssl_certificate_key'] = \"/etc/gitlab/ssl/pages-nginx.key\"\n</code></pre> <p>To use <code>HTTPS</code> add this information to your config. <code>/etc/gitlab/gitlab.rb</code>:</p> <pre><code>pages_external_url \"https://pages.sub1.uni-freiburg.de\" # not a subdomain of external_url\npages_nginx['redirect_http_to_https'] = true\n</code></pre> <p>If you support custom domains add this line to your config:</p> <pre><code>gitlab_pages['external_https'] = ['&lt;IP-ADDRESS-PAGES&gt;:443', '[2001:db8::2]:443'] # The secondary IPs for the GitLab Pages daemon\n</code></pre>"},{"location":"gitlab/#pages-access-control","title":"Pages Access Control","text":"<p>For access control of your Pages, add the following line to your config:</p> <pre><code>gitlab_pages['access_control'] = true\n</code></pre>"}]}